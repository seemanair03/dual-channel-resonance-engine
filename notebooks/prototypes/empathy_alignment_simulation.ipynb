{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0050dae",
   "metadata": {},
   "source": [
    "# Empathy Alignment Simulation\n",
    "### Modeling Realignment in Misaligned Attractor Fields  \n",
    "*“Not all pull is persuasion—some of it is resonance.”*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21241070",
   "metadata": {},
   "source": [
    "This notebook simulates an agent moving through a 2D space of competing attractors.  \n",
    "Each attractor has:\n",
    "- A spatial position  \n",
    "- A directional *intent* vector  \n",
    "- A base pull strength  \n",
    "\n",
    "The agent is influenced by all attractors, but their pull is **reweighted** by an empathy coefficient—a function of how aligned the agent’s heading is with the attractor’s intent (modeled via cosine similarity).\n",
    "\n",
    "This models systems that **correct** not by force, but by affinity—a dynamic form of fluid intelligence and ethical tuning.  \n",
    "Perfect for experiments inside the Dual-Channel Resonance Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4977da0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66fd7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class Attractor:\n",
    "    def __init__(self, position, intent, base_strength):\n",
    "        self.pos = np.array(position)\n",
    "        self.intent = self._normalize(np.array(intent))\n",
    "        self.base_strength = base_strength\n",
    "\n",
    "    def _normalize(self, vec):\n",
    "        norm = np.linalg.norm(vec)\n",
    "        return vec / norm if norm != 0 else vec\n",
    "\n",
    "    def pull(self, agent_pos, agent_heading):\n",
    "        direction = self.pos - agent_pos\n",
    "        dist = np.linalg.norm(direction)\n",
    "        if dist == 0:\n",
    "            return np.zeros(2)\n",
    "        \n",
    "        unit_dir = direction / dist\n",
    "        alignment = np.dot(agent_heading, self.intent)\n",
    "        empathy = (np.clip(alignment, -1, 1) + 1) / 2  # [0, 1]\n",
    "        strength = self.base_strength * empathy\n",
    "        return strength * unit_dir / (dist ** 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce71e6",
   "metadata": {},
   "source": [
    "### Agent Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f83240",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dt = 0.1\n",
    "steps = 200\n",
    "damping = 0.05\n",
    "\n",
    "# Define Attractors\n",
    "attractors = [\n",
    "    Attractor([4, 4], [1, 0], 1.2),\n",
    "    Attractor([-4, 4], [0, 1], 1.0),\n",
    "    Attractor([-3, -4], [1, 1], 0.7),\n",
    "    Attractor([3, -3], [-1, -1], 1.4)  # hostile intent\n",
    "]\n",
    "\n",
    "# Agent State\n",
    "pos = np.array([0.0, 0.0])\n",
    "vel = np.array([0.0, 0.0])\n",
    "trajectory = []\n",
    "\n",
    "for _ in range(steps):\n",
    "    heading = vel / np.linalg.norm(vel) if np.linalg.norm(vel) > 1e-4 else np.array([1.0, 0.0])\n",
    "    total_force = sum(a.pull(pos, heading) for a in attractors)\n",
    "    vel += total_force * dt\n",
    "    vel *= (1 - damping)\n",
    "    pos += vel * dt\n",
    "    trajectory.append(pos.copy())\n",
    "\n",
    "trajectory = np.array(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a43da",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9320f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "for a in attractors:\n",
    "    plt.plot(*a.pos, 'o', label='Attractor', alpha=0.7)\n",
    "plt.plot(trajectory[:, 0], trajectory[:, 1], 'k-', label='Agent Path')\n",
    "plt.title(\"Empathy-Weighted Realignment in Misaligned Fields\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d87a09",
   "metadata": {},
   "source": [
    "> This simulation belongs inside your Dual-Channel Resonance Engine.  \n",
    "> The agent’s behavior shows *ethical computation*: weighted not by dominance, but by alignment.\n",
    "\n",
    "To extend this:\n",
    "- Track empathy over time and plot the curve\n",
    "- Let attractor intents shift dynamically (semantic drift)\n",
    "- Feed pulse outputs into your embedding resonance visualizer\n",
    "\n",
    "Because in a world of loud vectors,  \n",
    "**empathy is the tuning fork.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
